{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-04 09:29:49,170 DEBUG : Loaded backend module://ipykernel.pylab.backend_inline version unknown.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "# import loader as L\n",
    "\n",
    "\n",
    "from scipy.interpolate import griddata, interp1d\n",
    "\n",
    "# from __future__ import print_function # (not needed in python3)\n",
    "\n",
    "from scipy.ndimage import rotate\n",
    "\n",
    "from functools import partial\n",
    "from math import sin, cos, pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "from braindecode.datasets.bbci import  BBCIDataset\n",
    "from collections import OrderedDict\n",
    "from braindecode.datautil.trial_segment import \\\n",
    "    create_signal_target_from_raw_mne\n",
    "from braindecode.mne_ext.signalproc import mne_apply, resample_cnt\n",
    "from braindecode.datautil.signalproc import highpass_cnt\n",
    "from braindecode.datautil.signalproc import exponential_running_standardize\n",
    "\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "log.setLevel('DEBUG')\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s : %(message)s',\n",
    "                 level=logging.DEBUG, stream=sys.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "locs = [[ 35.5,  -0.1 ],    # Fz\n",
    "        [ 12.2,  56.16],    # FC3\n",
    "        [  9.9,  27.6 ],    # FC1\n",
    "        [  9.4,  -0.1 ],    # FCz\n",
    "        [ 10.5, -28.32],    # FC2\n",
    "        [ 13  , -57   ],    # FC4\n",
    "        [-15.1,  87.48],    # C5\n",
    "        [-16.2,  57.48],    # C3\n",
    "        [-16.5,  28.44],    # C1\n",
    "        [-16.8, - 0.1 ],    # Cz\n",
    "        [-16.3, -29.64],    # C2\n",
    "        [-15.5, -58.68],    # C4\n",
    "        [-14.1, -87.6 ],    # C6\n",
    "        [-40.9,  53.16],    # CP3\n",
    "        [-39.3,  26.4 ],    # CP1\n",
    "        [-39.3, - 0.12],    # CPz\n",
    "        [-38.9, -27.84],    # CP2\n",
    "        [-40.2, -54.24],    # CP4\n",
    "        [-65.5,  22.08],    # P1\n",
    "        [-63.8, - 0.12],    # Pz\n",
    "        [-65.1, -23.28],    # P2\n",
    "        [-79.7, - 0.1 ]]    # POz\n",
    "\n",
    "locs = np.array(locs)\n",
    "\n",
    "channel_labels = ['Fz'\n",
    "        , 'FC3'\n",
    "        , 'FC1'\n",
    "        , 'FCz'\n",
    "        , 'FC2'\n",
    "        , 'FC4'\n",
    "        , 'C5'\n",
    "        , 'C3'\n",
    "        , 'C1'\n",
    "        , 'Cz'\n",
    "        , 'C2'\n",
    "        , 'C4'\n",
    "        , 'C6'\n",
    "        , 'CP3'\n",
    "        , 'CP1'\n",
    "        , 'CPz'\n",
    "        , 'CP2'\n",
    "        , 'CP4'\n",
    "        , 'P1'\n",
    "        , 'Pz'\n",
    "        , 'P2'\n",
    "        , 'POz'\n",
    "        ]\n",
    "\n",
    "\n",
    "gridsize = 32\n",
    "\n",
    "\n",
    "\n",
    "# features = L.train_set.X\n",
    "# labels = L.train_set.y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# channel_labels[0]  # highest\n",
    "# channel_labels[6]  # leftmost\n",
    "# channel_labels[12] # rightmost\n",
    "# channel_labels[21] # lowest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this now is a function, to find out min/max values of lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax(l: list) -> tuple:\n",
    "    assert len(l) > 0\n",
    "    minval = l[0]\n",
    "    maxval = l[0]\n",
    "    for v in l:\n",
    "        if v > maxval:\n",
    "            maxval = v\n",
    "        if v < minval:\n",
    "            minval = v\n",
    "    return (minval, maxval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fst(l: list) -> list:\n",
    "    return list(map(lambda v: v[0], l))\n",
    "\n",
    "def snd(l: list) -> list:\n",
    "    return list(map(lambda v: v[1], l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((-79.7, 35.5), (-87.6, 87.48))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minmax(fst(locs)), minmax(snd(locs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.519097222222222"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(87.5 * 2) / (79.7 + 35.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-22.1"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(-79.7 + 35.5) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "locsn = list(zip(map(lambda x: (x + 21.1) * 1.519, fst(locs)), snd(locs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(85.9754, -0.1),\n",
       " (50.582699999999996, 56.16),\n",
       " (47.089, 27.6),\n",
       " (46.329499999999996, -0.1),\n",
       " (48.0004, -28.32),\n",
       " (51.7979, -57.0),\n",
       " (9.114000000000003, 87.48),\n",
       " (7.443100000000003, 57.48),\n",
       " (6.987400000000002, 28.44),\n",
       " (6.531700000000001, -0.1),\n",
       " (7.291200000000001, -29.64),\n",
       " (8.506400000000001, -58.68),\n",
       " (10.633000000000003, -87.6),\n",
       " (-30.076199999999993, 53.16),\n",
       " (-27.64579999999999, 26.4),\n",
       " (-27.64579999999999, -0.12),\n",
       " (-27.038199999999993, -27.84),\n",
       " (-29.012900000000002, -54.24),\n",
       " (-67.44359999999999, 22.08),\n",
       " (-64.86129999999999, -0.12),\n",
       " (-66.83599999999998, -23.28),\n",
       " (-89.01339999999999, -0.1)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locsn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing rotation (and rescaling to square) before actually adding it to the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate2D(point: list) -> list:\n",
    "    degree = (45 * 2 * pi) / 360\n",
    "    return [point[0] * cos(degree) - point[1] * sin(degree), point[0] * sin(degree) + point[1] * cos(degree)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "locsr = np.array(list(map(rotate2D, locsn)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 60.86449903,  60.72307768],\n",
       "       [ -3.94374665,  75.47848701],\n",
       "       [ 13.78080406,  52.81309838],\n",
       "       [ 32.8306143 ,  32.68919294],\n",
       "       [ 53.96667238,  13.9161443 ],\n",
       "       [ 76.93173287,  -3.67844019],\n",
       "       [-55.41313001,  68.30227242],\n",
       "       [-35.3814313 ,  45.90756427],\n",
       "       [-15.16927893,  25.05095478],\n",
       "       [  4.68932004,   4.54789868],\n",
       "       [ 26.11430196, -15.80298803],\n",
       "       [ 47.50795904, -35.4780928 ],\n",
       "       [ 69.46122044, -54.42388763],\n",
       "       [-58.85688146,  16.32271152],\n",
       "       [-38.21615167,  -0.88091363],\n",
       "       [-19.46367984, -19.63338547],\n",
       "       [  0.56695822, -38.80474736],\n",
       "       [ 17.83825348, -58.86869014],\n",
       "       [-63.30274464, -32.07690918],\n",
       "       [-45.77901225, -45.94871788],\n",
       "       [-30.79874296, -63.72163469],\n",
       "       [-62.87126808, -63.01268943]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locsr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 35.5 ,  -0.1 ],\n",
       "       [ 12.2 ,  56.16],\n",
       "       [  9.9 ,  27.6 ],\n",
       "       [  9.4 ,  -0.1 ],\n",
       "       [ 10.5 , -28.32],\n",
       "       [ 13.  , -57.  ],\n",
       "       [-15.1 ,  87.48],\n",
       "       [-16.2 ,  57.48],\n",
       "       [-16.5 ,  28.44],\n",
       "       [-16.8 ,  -0.1 ],\n",
       "       [-16.3 , -29.64],\n",
       "       [-15.5 , -58.68],\n",
       "       [-14.1 , -87.6 ],\n",
       "       [-40.9 ,  53.16],\n",
       "       [-39.3 ,  26.4 ],\n",
       "       [-39.3 ,  -0.12],\n",
       "       [-38.9 , -27.84],\n",
       "       [-40.2 , -54.24],\n",
       "       [-65.5 ,  22.08],\n",
       "       [-63.8 ,  -0.12],\n",
       "       [-65.1 , -23.28],\n",
       "       [-79.7 ,  -0.1 ]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def gen_images(locs, features, n_gridpoints, normalize=True,\n",
    "#                augment=False, pca=False, std_mult=0.1, n_components=2, edgeless=False):\n",
    "# needs defined: locs, features, n_gridpoints\n",
    "\n",
    "def interpolate(locs, features, n_gridpoints=32, rotate=True, edge_channels=[0, 6, 12, 21]):\n",
    "    \"\"\"\n",
    "    Generates EEG images given electrode locations in 2D space and multiple feature values for each electrode\n",
    "\n",
    "    :param locs: An array with shape [n_electrodes, 2] containing X, Y coordinates for each electrode.\n",
    "    :param features: Feature matrix as [n_samples, n_features]\n",
    "                        Features are as columns.\n",
    "                        Features corresponding to each frequency band are concatenated.\n",
    "                        (alpha1, alpha2, ..., beta1, beta2,...)\n",
    "    :param n_gridpoints: Number of pixels in the output images\n",
    "    :rotate: If the whole image should be rotated by 45 degrees and fit to a square.\n",
    "    :edge_channels: The indices of the channels with the\n",
    "                    highest, leftmost, rightmost and lowest coordinates.\n",
    "                    Only relevant when rotating.\n",
    "                    (Assuming that Fz is on the x axis to the right.)\n",
    "    \n",
    "    :return:            Tensor of size [samples, colors, W, H] containing generated\n",
    "                        images.\n",
    "    \"\"\"\n",
    "    \n",
    "    if rotate:\n",
    "        high_x = locs[edge_channels[0]][0]\n",
    "        high_y = locs[edge_channels[1]][1]\n",
    "        low_y  = locs[edge_channels[2]][1]\n",
    "        low_x  = locs[edge_channels[3]][0]\n",
    "        \n",
    "        t_x = abs(high_x) + abs(low_x)\n",
    "        t_y = abs(high_y) + abs(low_y)\n",
    "        \n",
    "        factor = t_y / t_x\n",
    "        \n",
    "        # centering:\n",
    "        xdiff = (high_x + low_x) / 2\n",
    "        ydiff = (high_y + low_y) / 2\n",
    "        \n",
    "        locst = zip(map(lambda x: (x - xdiff) * factor, fst(locs)),\n",
    "                    map(lambda y: (y - ydiff), snd(locs)))\n",
    "        \n",
    "        locs = np.array(list(map(rotate2D, locst)))\n",
    "    \n",
    "    cut = lambda a: a if len(a.shape) < 3 else a[:, :, 0]\n",
    "    \n",
    "    feat_array_temp = []\n",
    "    nElectrodes = locs.shape[0]     # Number of electrodes\n",
    "    # Test whether the feature vector length is divisible by number of electrodes\n",
    "    assert features.shape[1] % nElectrodes == 0\n",
    "    n_colors = int(features.shape[1] / nElectrodes)\n",
    "    for c in range(n_colors):\n",
    "        feat_array_temp.append(cut(features[:, c * nElectrodes : nElectrodes * (c+1)]))\n",
    "    nSamples = features.shape[0]\n",
    "    # getting some surrounding values right\n",
    "    grid_x, grid_y = np.mgrid[\n",
    "                     min(locs[:, 0]):max(locs[:, 0]):n_gridpoints*1j,\n",
    "                     min(locs[:, 1]):max(locs[:, 1]):n_gridpoints*1j\n",
    "                     ]\n",
    "    temp_interp = []\n",
    "    for c in range(n_colors):\n",
    "        temp_interp.append(np.zeros([nSamples, n_gridpoints, n_gridpoints]))\n",
    "    # Interpolating\n",
    "    for i in range(nSamples):\n",
    "        for c in range(n_colors):\n",
    "            temp_interp[c][i, :, :] = cut(griddata(locs, feat_array_temp[c][i, :], (grid_x, grid_y),\n",
    "                                    method='cubic', fill_value=np.nan))\n",
    "    #                                 method='cubic', fill_value=np.nan)# [:, :, 0]\n",
    "    #                                 method='cubic', fill_value=np.nan)\n",
    "        print('Interpolating {0}/{1}'.format(i+1, nSamples), end='\\r')\n",
    "    images = np.swapaxes(np.asarray(temp_interp), 0, 1)     # swap axes to have [samples, colors, W, H]\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images = interpolate(locsr, features, gridsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-79.7, 35.5)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b = minmax(fst(locs))\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-44.2"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-57.6"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a - (a + b) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57.6"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b - (a + b) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mx = interp1d(minmax(fst(locs)), [0, gridsize])\n",
    "# my = interp1d(minmax(snd(locs)), [0, gridsize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx = interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images2 = images[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(images.shape[0]):\n",
    "#     print('Saving {0}/{1}'.format(i+1, images.shape[0]), end='\\r')\n",
    "#     # for i in range(22):\n",
    "#     #     plt.text(my(locsr[i][1]), mx(locsr[i][0]), channel_labels[i])\n",
    "#     plt.imshow(images[i,0,:,:], cmap='RdYlBu') # , interpolation='bilinear')\n",
    "#     plt.savefig(os.path.join('images3/','%d.png' % i))\n",
    "#     plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# plt.imshow(rotate(images[i,0,:,:], 45, cval=np.nan, prefilter=False), cmap='RdYlBu')\n",
    "# plt.savefig(os.path.join('images4/','%d.png' % i))\n",
    "# plt.show()\n",
    "# plt.close()\n",
    "# plt.imshow(images[i,0,:,:], cmap='RdYlBu')\n",
    "# plt.show()\n",
    "# plt.close()\n",
    "# # plt.savefig(os.path.join('images4/','%d.png' % i))\n",
    "# # plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "tight_cap_positions = [\n",
    "    ['', '', '', '', 'Fp1', 'FPz', 'Fp2', '', '', '', ''],\n",
    "    ['', '', '', 'AFp3h', '', '', '', 'Afp4h', '', '', ''],\n",
    "    ['', 'AF7', 'AF5', 'AF3', 'AF1', 'AFz', 'AF2', 'AF4', 'AF6', 'AF8', ''],\n",
    "    ['', '', 'AFF5h', '', 'AFF1', '', 'AFF2', '', 'AFF6h', '', ''],\n",
    "    ['', 'F7', 'F5', 'F3', 'F1', 'Fz', 'F2', 'F4', 'F6', 'F8', ''],\n",
    "    ['FFT9h', 'FFT7h', 'FFC5h', 'FFC3h', 'FFC1h', '', 'FFC2h', 'FFC4h', 'FFC6h', 'FFT8h', 'FFT10h'],\n",
    "    ['FT9', 'FT7', 'FC5', 'FC3', 'FC1', 'FCz', 'FC2', 'FC4', 'FC6', 'FT8', 'FT10'],\n",
    "    ['FTT9h', 'FTT7h', 'FCC5h', 'FCC3h', 'FCC1h', '', 'FCC2h', 'FCC4h', 'FCC6h', 'FTT8h', 'FTT10h'],\n",
    "    ['M1', 'T7', 'C5', 'C3', 'C1', 'Cz', 'C2', 'C4', 'C6', 'T8', 'M2'],\n",
    "    ['', 'TTP7h', 'CCP5h', 'CCP3h', 'CCP1h', '', 'CCP2h', 'CCP4h', 'CCP6h', 'TTP8h', ''],\n",
    "    ['TP9', 'TP7', 'CP5', 'CP3', 'CP1', 'CPz', 'CP2', 'CP4', 'CP6', 'TP8', 'TP10'],\n",
    "    ['TPP9h', 'TPP7h', 'CPP5h', 'CPP3h', 'CPP1h', '', 'CPP2h', 'CPP4h', 'CPP6h', 'TPP8h', 'TPP10h'],\n",
    "    ['P9', 'P7', 'P5', 'P3', 'P1', 'Pz', 'P2', 'P4', 'P6', 'P8', 'P10'],\n",
    "    ['PPO9h', '', 'PPO5h', '', 'PPO1', '', 'PPO2', '', 'PPO6h', '', 'PPO10h'],\n",
    "    ['PO9', 'PO7', 'PO5', 'PO3', 'PO1', 'POz', 'PO2', 'PO4', 'PO6', 'PO8', 'PO10'],\n",
    "    ['POO9h', '', '', 'POO3h', '', '', '', 'POO4h', '', '', 'POO10h'],\n",
    "    ['', '', '', '', 'O1', 'Oz', 'O2', '', '', '', ''],\n",
    "    ['', '', '', '', 'OI1h', '', 'OI2h', '', '', '', ''],\n",
    "    ['', '', '', '', 'I1', 'Iz', 'I2', '', '', '', '']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapper(locs):\n",
    "    def actual(values):\n",
    "        nmap = np.empty((19, 11))\n",
    "        for i, row in enumerate(tight_cap_positions):\n",
    "            for j, col in enumerate(row):\n",
    "                if col in locs:\n",
    "                    ind = locs.index(col)\n",
    "                    nmap[i, j] = values[ind]\n",
    "                else:\n",
    "                    nmap[i, j] = np.nan\n",
    "        return nmap\n",
    "    return actual\n",
    "\n",
    "# TODO: this can be heavily optimized with linear algebra.\n",
    "# This is a big but simple matrix basically.\n",
    "\n",
    "def mapper2(locs):\n",
    "    res = mapper(locs)(list(range(len(locs))))\n",
    "    res = res.reshape(209)\n",
    "    matrix = np.zeros((209, 129))\n",
    "    for i, value in enumerate(res):\n",
    "        if not np.isnan(value):\n",
    "            matrix[i, int(value)] = 1\n",
    "    return lambda v: matrix.dot(v).reshape((19, 11))\n",
    "    \n",
    "    # this version is building one big matrix\n",
    "\n",
    "# r = mapper2(positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = mapper(channel_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(1, 3)\n",
    "\n",
    "# ax[0].imshow(a(features[0, :, 0]), cmap='RdYlBu', interpolation='nearest')\n",
    "# ax[1].imshow(a(features[0, :, 0]), cmap='RdYlBu', interpolation='bilinear')\n",
    "# ax[2].imshow(a(features[0, :, 0]), cmap='RdYlBu', interpolation='bicubic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(a(features[0, :, 0]), cmap='RdYlBu', interpolation='nearest')\n",
    "# plt.imshow(a(features[0, :, 0]), cmap='RdYlBu')\n",
    "# list(zip(a(features[0, :, 0])[~np.isnan(a(features[0, :, 0]))],np.argwhere(~np.isnan(a(features[0, :, 0])))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# points = list(map(tuple, np.argwhere(~np.isnan(a(features[0, :, 0])))))\n",
    "# values = a(features[0, :, 0])[~np.isnan(a(features[0, :, 0]))]\n",
    "# image = griddata(points, values, tuple(np.mgrid[0:19, 0:11]), method='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(image, cmap='RdYlBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_bbci_data(filename, low_cut_hz, debug=False):\n",
    "    load_sensor_names = None\n",
    "    if debug:\n",
    "        load_sensor_names = ['C3', 'C4', 'C2']\n",
    "    # we loaded all sensors to always get same cleaning results independent of sensor selection\n",
    "    # There is an inbuilt heuristic that tries to use only EEG channels and that definitely\n",
    "    # works for datasets in our paper\n",
    "    loader = BBCIDataset(filename, load_sensor_names=load_sensor_names)\n",
    "\n",
    "    log.info(\"Loading data...\")\n",
    "    cnt = loader.load()\n",
    "\n",
    "    # Cleaning: First find all trials that have absolute microvolt values\n",
    "    # larger than +- 800 inside them and remember them for removal later\n",
    "    log.info(\"Cutting trials...\")\n",
    "\n",
    "    marker_def = OrderedDict([('Right Hand', [1]), ('Left Hand', [2],),\n",
    "                              ('Rest', [3]), ('Feet', [4])])\n",
    "    clean_ival = [0, 4000]\n",
    "\n",
    "    set_for_cleaning = create_signal_target_from_raw_mne(cnt, marker_def,\n",
    "                                                  clean_ival)\n",
    "\n",
    "    clean_trial_mask = np.max(np.abs(set_for_cleaning.X), axis=(1, 2)) < 800\n",
    "\n",
    "    log.info(\"Clean trials: {:3d}  of {:3d} ({:5.1f}%)\".format(\n",
    "        np.sum(clean_trial_mask),\n",
    "        len(set_for_cleaning.X),\n",
    "        np.mean(clean_trial_mask) * 100))\n",
    "\n",
    "    # now pick only sensors with C in their name\n",
    "    # as they cover motor cortex\n",
    "    C_sensors = ['FC5', 'FC1', 'FC2', 'FC6', 'C3', 'C4', 'CP5',\n",
    "                 'CP1', 'CP2', 'CP6', 'FC3', 'FCz', 'FC4', 'C5', 'C1', 'C2',\n",
    "                 'C6',\n",
    "                 'CP3', 'CPz', 'CP4', 'FFC5h', 'FFC3h', 'FFC4h', 'FFC6h',\n",
    "                 'FCC5h',\n",
    "                 'FCC3h', 'FCC4h', 'FCC6h', 'CCP5h', 'CCP3h', 'CCP4h', 'CCP6h',\n",
    "                 'CPP5h',\n",
    "                 'CPP3h', 'CPP4h', 'CPP6h', 'FFC1h', 'FFC2h', 'FCC1h', 'FCC2h',\n",
    "                 'CCP1h',\n",
    "                 'CCP2h', 'CPP1h', 'CPP2h']\n",
    "    if debug:\n",
    "        C_sensors = load_sensor_names\n",
    "    # cnt = cnt.pick_channels(C_sensors)\n",
    "\n",
    "    # Further preprocessings as descibed in paper\n",
    "    log.info(\"Resampling...\")\n",
    "    # cnt = resample_cnt(cnt, 250.0)\n",
    "    cnt = resample_cnt(cnt, 50.0)\n",
    "    log.info(\"Highpassing...\")\n",
    "    cnt = mne_apply(\n",
    "        lambda a: highpass_cnt(\n",
    "            a, low_cut_hz, cnt.info['sfreq'], filt_order=3, axis=1),\n",
    "        cnt)\n",
    "    log.info(\"Standardizing...\")\n",
    "    cnt = mne_apply(\n",
    "        lambda a: exponential_running_standardize(a.T, factor_new=1e-3,\n",
    "                                                  init_block_size=1000,\n",
    "                                                  eps=1e-4).T,\n",
    "        cnt)\n",
    "\n",
    "    # Trial interval, start at -500 already, since improved decoding for networks\n",
    "    ival = [-500, 4000]\n",
    "\n",
    "    dataset = create_signal_target_from_raw_mne(cnt, marker_def, ival)\n",
    "    dataset.X = dataset.X[clean_trial_mask]\n",
    "    dataset.y = dataset.y[clean_trial_mask]\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = \"/datadisk/Coding/high-gamma-dataset/data/train/1.mat\"\n",
    "# filename_template = \"/media/ced/HDD/Coding/high-gamma-dataset/data/%s/%i.mat\"\n",
    "# filename_train = filename_template % ('train', 2)\n",
    "# filename_test = filename_template % ('test', 2)\n",
    "# low_cut_hz = 4\n",
    "# train = load_bbci_data(filename=filename_train, low_cut_hz=low_cut_hz)\n",
    "# test = load_bbci_data(filename=filename_test, low_cut_hz=low_cut_hz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = train.X[0, :, 0]\n",
    "# d = d - d.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = [\n",
    " 'Fp1', 'Fp2', 'Fpz', 'F7', 'F3', 'Fz', 'F4', 'F8', 'FC5',\n",
    " 'FC1', 'FC2', 'FC6', 'M1', 'T7', 'C3', 'Cz', 'C4', 'T8', 'M2',\n",
    " 'CP5', 'CP1', 'CP2', 'CP6', 'P7', 'P3', 'Pz', 'P4', 'P8', 'POz',\n",
    " 'O1', 'Oz', 'O2', 'AF7', 'AF3', 'AF4', 'AF8', 'F5', 'F1',\n",
    " 'F2', 'F6', 'FC3', 'FCz', 'FC4', 'C5', 'C1', 'C2', 'C6', 'CP3',\n",
    " 'CPz', 'CP4', 'P5', 'P1', 'P2', 'P6', 'PO5', 'PO3', 'PO4', 'PO6',\n",
    " 'FT7', 'FT8', 'TP7', 'TP8', 'PO7', 'PO8', 'FT9', 'FT10', 'TPP9h',\n",
    " 'TPP10h', 'PO9', 'PO10', 'P9', 'P10', 'AFF1', 'AFz', 'AFF2', 'FFC5h',\n",
    " 'FFC3h', 'FFC4h', 'FFC6h', 'FCC5h', 'FCC3h', 'FCC4h', 'FCC6h',\n",
    " 'CCP5h', 'CCP3h', 'CCP4h', 'CCP6h', 'CPP5h', 'CPP3h', 'CPP4h',\n",
    " 'CPP6h', 'PPO1', 'PPO2', 'I1', 'Iz', 'I2', 'AFp3h', 'AFp4h', 'AFF5h',\n",
    " 'AFF6h', 'FFT7h', 'FFC1h', 'FFC2h', 'FFT8h', 'FTT9h', 'FTT7h',\n",
    " 'FCC1h', 'FCC2h', 'FTT8h', 'FTT10h', 'TTP7h', 'CCP1h', 'CCP2h',\n",
    " 'TTP8h', 'TPP7h', 'CPP1h', 'CPP2h', 'TPP8h', 'PPO9h', 'PPO5h',\n",
    " 'PPO6h', 'PPO10h', 'POO9h', 'POO3h', 'POO4h', 'POO10h', 'OI1h',\n",
    " 'OI2h', 'STI 014']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = mapper(positions)\n",
    "r = mapper2(positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rpoints = list(map(tuple, np.argwhere(~np.isnan(r(d)))))\n",
    "# rvalues = r(d)[~np.isnan(r(d))]\n",
    "# rimage = griddata(points, values, tuple(np.mgrid[0:19, 0:11]), method='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# points = list(map(tuple, np.argwhere(~np.isnan(b(d)))))\n",
    "# values = b(d)[~np.isnan(b(d))]\n",
    "# image = griddata(points, values, tuple(np.mgrid[0:19, 0:11]), method='linear')\n",
    "# values = values.reshape(1, 126)\n",
    "# image2 = interpolate(np.array(points), values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(b(d), cmap='RdYlBu')\n",
    "# plt.imshow(rimage, cmap='RdYlBu')\n",
    "# plt.imshow(image2[0, 0], cmap='RdYlBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.X.shape, train.y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate2(features, ch_names=None, ch_mapper=None, grid_x=11, grid_y=19):\n",
    "    assert ch_mapper or ch_names, \"needs either channel names or a mapper instance!\"\n",
    "    if not ch_mapper:\n",
    "        ch_mapper = mapper(ch_names)\n",
    "\n",
    "    locs = list(map(tuple, np.argwhere(~np.isnan(ch_mapper(features[0, :, 0])))))\n",
    "\n",
    "    result = np.empty((features.shape[0], grid_y * grid_x, features.shape[2]))\n",
    "\n",
    "    for trial in range(features.shape[0]):\n",
    "        for frame in range(features.shape[2]):\n",
    "            r = ch_mapper(features[trial, :, frame])\n",
    "            res = griddata(locs, r[~np.isnan(r)], tuple(np.mgrid[0:grid_y, 0:grid_x]), method='linear')\n",
    "            res = res.reshape(grid_y * grid_x)\n",
    "            result[trial, :, frame] = res\n",
    "\n",
    "        print(\"Interpolating: %s/%s\" % (trial, features.shape[0]), end='\\r')\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images = interpolate2(data.X, ch_mapper=b)\n",
    "# with open('images_hgd', 'wb') as f:\n",
    "#     pickle.dump(images, f)\n",
    "# with open('images_test_hgd', 'wb') as f:\n",
    "#     pickle.dump(images_test, f)\n",
    "# with open('labels_hgd', 'wb') as f:\n",
    "#     pickle.dump(labels, f)\n",
    "# with open('labels_test_hgd', 'wb') as f:\n",
    "#     pickle.dump(labels_test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# massive speedup compared to before.\n",
    "import pickle\n",
    "try:\n",
    "    with open('images_hgd', 'rb') as f:\n",
    "        images = pickle.load(f)\n",
    "    with open('images_test_hgd', 'rb') as f:\n",
    "        images_test = pickle.load(f)\n",
    "    with open('labels_test_hgd', 'rb') as f:\n",
    "        labels_test = pickle.load(f)\n",
    "    with open('labels_hgd', 'rb') as f:\n",
    "        labels = pickle.load(f)\n",
    "except:\n",
    "    images = interpolate2(train.X, ch_mapper=r)\n",
    "    images_test = interpolate2(test.X, ch_mapper=r)\n",
    "    print('please relabel stuff!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# teststuff = interpolate2(test.X, ch_mapper=r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, Conv1D, Conv2D, Flatten, Dropout, Activation, MaxPooling2D, Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# they are being loaded by pickle before\n",
    "\n",
    "# labels = keras.utils.to_categorical(train.y, num_classes=4)\n",
    "# labels_test = keras.utils.to_categorical(test.y, num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l = np.argwhere(~np.isnan(images))\n",
    "# images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images[np.isnan(images)] = 0\n",
    "# images_test[np.isnan(images_test)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(model.layers)):\n",
    "#     print(type(model.layers[i]), model.layers[i].input_shape, model.layers[i].output_shape)\n",
    "# model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "\n",
    "# model.add(Reshape((19, 11, 225)))\n",
    "# model.add(Conv1D(16, 1, # input_shape=(19, 11, 225)\n",
    "#                  input_shape=(209, 225),\n",
    "#                  data_format='channels_last'))  # (None, 209, 255)\n",
    "# model.add(Reshape((19, 11, -1)))\n",
    "# model.add(Conv2D(64, (3, 3)))\n",
    "# model.add(MaxPooling2D())\n",
    "# model.add(Conv2D(32, (3, 3)))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(40, activation='relu'))\n",
    "# model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "\n",
    "# model.add(Reshape((19, 11, 225)))\n",
    "# model.add(Conv2D(64, (1, 5))) # , input_shape=(19, 11, 225)))\n",
    "#                  # data_format='channels_last'))\n",
    "# model.add(MaxPooling2D())\n",
    "# model.add(Conv2D(16, (3, 3), data_format='channels_last'))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(40, activation='relu'))\n",
    "# model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "\n",
    "\n",
    "# model.compile('sgd', metrics=['accuracy'], loss='categorical_crossentropy')\n",
    "# hist = model.fit(images, labels, epochs=25,\n",
    "#                  # validation_split=0.1\n",
    "#                  validation_data = (images_test, labels_test)\n",
    "#                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.evaluate(images_test, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = hist\n",
    "# # summarize history for accuracy\n",
    "# plt.plot(history.history['acc'])\n",
    "# plt.plot(history.history['val_acc'])\n",
    "# plt.title('model accuracy')\n",
    "# plt.ylabel('accuracy')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'test'], loc='upper left')\n",
    "# plt.show()\n",
    "# # summarize history for loss\n",
    "# plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "# plt.title('model loss')\n",
    "# plt.ylabel('loss')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'test'], loc='upper left')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Conv1D(32, 6))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Conv2D(16, (3, 3)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile('adam', metrics=['accuracy'], loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist = model.fit(images, labels, epochs=5, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
