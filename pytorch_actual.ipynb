{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from actual.ipynb\n",
      "2019-07-24 17:59:43,297 DEBUG : Loaded backend module://ipykernel.pylab.backend_inline version unknown.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import importlib\n",
    "importlib.reload(logging) # see https://stackoverflow.com/a/21475297/1469195\n",
    "log = logging.getLogger()\n",
    "log.setLevel('INFO')\n",
    "import sys\n",
    "import import_ipynb\n",
    "import actual\n",
    "\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s : %(message)s',\n",
    "                     level=logging.INFO, stream=sys.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import os\n",
    "import site\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import logging\n",
    "log = logging.getLogger()\n",
    "log.setLevel('INFO')\n",
    "import sys\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s : %(message)s',\n",
    "                     level=logging.INFO, stream=sys.stdout)\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'png'\n",
    "matplotlib.rcParams['figure.figsize'] = (12.0, 1.0)\n",
    "matplotlib.rcParams['font.size'] = 14\n",
    "import seaborn\n",
    "seaborn.set_style('darkgrid')\n",
    "\n",
    "from numpy.random import RandomState\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import copy\n",
    "import math\n",
    "\n",
    "import itertools\n",
    "import torch as th\n",
    "from braindecode.torch_ext.util import np_to_var, var_to_np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_examples = 20\n",
    "n_time_steps = 100\n",
    "n_width = 11\n",
    "n_height = 19\n",
    "inputs = th.ones(n_examples, 1, n_time_steps, n_width * n_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = (torch.tensor(actual.images, dtype=torch.float).view(811, 11, 1, 19, 225), torch.tensor(actual.labels))\n",
    "\n",
    "# trainloader = torch.utils.data.DataLoader(trainset, batch_size=12,\n",
    "#                                           shuffle=True, num_workers=4)\n",
    "\n",
    "\n",
    "testdata = (torch.tensor(actual.images_test, dtype=torch.float).view(160, 11, 1, 19, 225), torch.tensor(actual.labels_test))\n",
    "\n",
    "# testloader = torch.utils.data.DataLoader(testset, batch_size=12,\n",
    "#                                         shuffle=False, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 15, kernel_size=(1, 21), stride=(1, 1))\n",
       "  (conv2): Conv2d(15, 32, kernel_size=(1, 21), stride=(1, 1))\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(1, 21), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=13376, out_features=500, bias=True)\n",
       "  (fc2): Linear(in_features=500, out_features=100, bias=True)\n",
       "  (fc3): Linear(in_features=100, out_features=20, bias=True)\n",
       "  (fc4): Linear(in_features=20, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_filters = 15\n",
    "n_filters_2 = 32\n",
    "n_filters_3 = 64\n",
    "n_filters_4 = 128\n",
    "kernel_size = (1, 21)\n",
    "\n",
    "# continue: process time dimension several steps,\n",
    "# then remove it by meaning across time\n",
    "# -> n_examples x n_conv_out_filters x (width * height)\n",
    "# -> transform back to:\n",
    "# n_examples x n_conv_out_filters x width x height\n",
    "# -> now it is a normal \"image\" problem\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, n_filters, kernel_size)\n",
    "        self.conv2 = nn.Conv2d(n_filters, n_filters_2, kernel_size)\n",
    "        self.conv3 = nn.Conv2d(n_filters_2, n_filters_3, kernel_size)\n",
    "        # self.conv4 = nn.Conv2d(n_filters_3, n_filters_4, kernel_size)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(n_filters_3 * 209, 500)\n",
    "        self.fc2 = nn.Linear(500, 100)\n",
    "        self.fc3 = nn.Linear(100, 20)\n",
    "        self.fc4 = nn.Linear(20, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (1, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (1, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)), (1, 2))\n",
    "        x = torch.mean(x, -1)\n",
    "        # print(x.size())\n",
    "        # x = F.max_pool2d(F.relu(self.conv4(x)), 2)\n",
    "        # x = x.view(-1, self.num_flat_features(x))\n",
    "        x = x.view(-1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc4(self.fc3(x)))\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net = Net()\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "d, l = traindata\n",
    "# print(e) # [19, 1, 11, 225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0092, 0.0864, 0.1272, 0.1833], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "\n",
    "\n",
    "o = net(d[i].to(device))\n",
    "print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2007, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "loss = criterion(o, l[i].to(device))\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.CrossEntropyLoss?\n",
    "# nn.MSELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200] loss: 0.005\n",
      "[1,   400] loss: 0.005\n",
      "[1,   600] loss: 0.008\n",
      "[1,   800] loss: 0.009\n",
      "[2,   200] loss: 0.005\n",
      "[2,   400] loss: 0.005\n",
      "[2,   600] loss: 0.007\n",
      "[2,   800] loss: 0.007\n",
      "[3,   200] loss: 0.005\n",
      "[3,   400] loss: 0.004\n",
      "[3,   600] loss: 0.007\n",
      "[3,   800] loss: 0.007\n",
      "[4,   200] loss: 0.005\n",
      "[4,   400] loss: 0.004\n",
      "[4,   600] loss: 0.005\n",
      "[4,   800] loss: 0.005\n",
      "[5,   200] loss: 0.005\n",
      "[5,   400] loss: 0.003\n",
      "[5,   600] loss: 0.005\n",
      "[5,   800] loss: 0.009\n",
      "[6,   200] loss: 0.005\n",
      "[6,   400] loss: 0.004\n",
      "[6,   600] loss: 0.005\n",
      "[6,   800] loss: 0.004\n",
      "[7,   200] loss: 0.003\n",
      "[7,   400] loss: 0.003\n",
      "[7,   600] loss: 0.003\n",
      "[7,   800] loss: 0.003\n",
      "[8,   200] loss: 0.003\n",
      "[8,   400] loss: 0.004\n",
      "[8,   600] loss: 0.003\n",
      "[8,   800] loss: 0.005\n",
      "[9,   200] loss: 0.003\n",
      "[9,   400] loss: 0.001\n",
      "[9,   600] loss: 0.003\n",
      "[9,   800] loss: 0.005\n",
      "[10,   200] loss: 0.003\n",
      "[10,   400] loss: 0.001\n",
      "[10,   600] loss: 0.002\n",
      "[10,   800] loss: 0.004\n",
      "[11,   200] loss: 0.003\n",
      "[11,   400] loss: 0.001\n",
      "[11,   600] loss: 0.002\n",
      "[11,   800] loss: 0.004\n",
      "[12,   200] loss: 0.003\n",
      "[12,   400] loss: 0.001\n",
      "[12,   600] loss: 0.002\n",
      "[12,   800] loss: 0.003\n",
      "[13,   200] loss: 0.003\n",
      "[13,   400] loss: 0.001\n",
      "[13,   600] loss: 0.002\n",
      "[13,   800] loss: 0.003\n",
      "[14,   200] loss: 0.002\n",
      "[14,   400] loss: 0.001\n",
      "[14,   600] loss: 0.002\n",
      "[14,   800] loss: 0.002\n",
      "[15,   200] loss: 0.002\n",
      "[15,   400] loss: 0.001\n",
      "[15,   600] loss: 0.002\n",
      "[15,   800] loss: 0.003\n",
      "[16,   200] loss: 0.002\n",
      "[16,   400] loss: 0.000\n",
      "[16,   600] loss: 0.002\n",
      "[16,   800] loss: 0.002\n",
      "[17,   200] loss: 0.002\n",
      "[17,   400] loss: 0.000\n",
      "[17,   600] loss: 0.002\n",
      "[17,   800] loss: 0.002\n",
      "[18,   200] loss: 0.002\n",
      "[18,   400] loss: 0.000\n",
      "[18,   600] loss: 0.002\n",
      "[18,   800] loss: 0.002\n",
      "[19,   200] loss: 0.002\n",
      "[19,   400] loss: 0.000\n",
      "[19,   600] loss: 0.002\n",
      "[19,   800] loss: 0.002\n",
      "[20,   200] loss: 0.002\n",
      "[20,   400] loss: 0.000\n",
      "[20,   600] loss: 0.002\n",
      "[20,   800] loss: 0.002\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i in range(traindata[0].shape[0]):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        \n",
    "        inputs, labels = traindata[0][i].to(device), traindata[1][i].to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 199:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 200))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 160 test images: 59 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "timages, tlabels = testdata\n",
    "with torch.no_grad():\n",
    "    for i in range(testdata[0].shape[0]):\n",
    "        images, labels = timages[i].to(device), tlabels[i].to(device)\n",
    "        outputs = net(images)\n",
    "        predicted = torch.max(outputs.data)\n",
    "        total += labels.size(0)\n",
    "        correct += (outputs == labels).sum().item()\n",
    "        # print(outputs, labels)\n",
    "\n",
    "print('Accuracy of the network on the %d test images: %d %%' % (\n",
    "    testdata[0].shape[0], 100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3460, 0.4153, 0.2221, 0.0000], device='cuda:0')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
