{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "# import loader as L\n",
    "\n",
    "\n",
    "from scipy.interpolate import griddata, interp1d\n",
    "\n",
    "from scipy.ndimage import rotate\n",
    "\n",
    "from functools import partial\n",
    "from math import sin, cos, pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "from braindecode.datasets.bbci import  BBCIDataset\n",
    "from collections import OrderedDict\n",
    "from braindecode.datautil.trial_segment import \\\n",
    "    create_signal_target_from_raw_mne\n",
    "from braindecode.mne_ext.signalproc import mne_apply, resample_cnt\n",
    "from braindecode.datautil.signalproc import highpass_cnt\n",
    "from braindecode.datautil.signalproc import exponential_running_standardize\n",
    "\n",
    "import torch\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "log.setLevel('DEBUG')\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s : %(message)s',\n",
    "                 level=logging.DEBUG, stream=sys.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## These are the relative locations of the\n",
    "## corresponding channels (as a comment, to the right).\n",
    "## The input channel data is supposed to be in this order.\n",
    "locs = [[ 35.5,  -0.1 ],    # Fz\n",
    "        [ 12.2,  56.16],    # FC3\n",
    "        [  9.9,  27.6 ],    # FC1\n",
    "        [  9.4,  -0.1 ],    # FCz\n",
    "        [ 10.5, -28.32],    # FC2\n",
    "        [ 13  , -57   ],    # FC4\n",
    "        [-15.1,  87.48],    # C5\n",
    "        [-16.2,  57.48],    # C3\n",
    "        [-16.5,  28.44],    # C1\n",
    "        [-16.8, - 0.1 ],    # Cz\n",
    "        [-16.3, -29.64],    # C2\n",
    "        [-15.5, -58.68],    # C4\n",
    "        [-14.1, -87.6 ],    # C6\n",
    "        [-40.9,  53.16],    # CP3\n",
    "        [-39.3,  26.4 ],    # CP1\n",
    "        [-39.3, - 0.12],    # CPz\n",
    "        [-38.9, -27.84],    # CP2\n",
    "        [-40.2, -54.24],    # CP4\n",
    "        [-65.5,  22.08],    # P1\n",
    "        [-63.8, - 0.12],    # Pz\n",
    "        [-65.1, -23.28],    # P2\n",
    "        [-79.7, - 0.1 ]]    # POz\n",
    "\n",
    "# conversion to an np-array, because further manipulation will happen\n",
    "# in combination wit other arrys.\n",
    "locs = np.array(locs)\n",
    "\n",
    "# labels for the locations of the aforementioned channels\n",
    "channel_labels = ['Fz'\n",
    "        , 'FC3'\n",
    "        , 'FC1'\n",
    "        , 'FCz'\n",
    "        , 'FC2'\n",
    "        , 'FC4'\n",
    "        , 'C5'\n",
    "        , 'C3'\n",
    "        , 'C1'\n",
    "        , 'Cz'\n",
    "        , 'C2'\n",
    "        , 'C4'\n",
    "        , 'C6'\n",
    "        , 'CP3'\n",
    "        , 'CP1'\n",
    "        , 'CPz'\n",
    "        , 'CP2'\n",
    "        , 'CP4'\n",
    "        , 'P1'\n",
    "        , 'Pz'\n",
    "        , 'P2'\n",
    "        , 'POz'\n",
    "        ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate2D(point: list) -> list:\n",
    "    \"\"\" Function to rotate a given point by 45°.\n",
    "    This is the classic rotational matrix given by\n",
    "    [cos(ϕ) -sin(ϕ)]\n",
    "    [sin(ϕ)  cos(ϕ)]\n",
    "    multiplied with the point.\n",
    "    \n",
    "    Args:\n",
    "        point (list): Two elements. also works with any other iterable type with at least two elements.\n",
    "        \n",
    "    Returns:\n",
    "        point (list): Two elements, their location rotated by 45° around the center.\n",
    "        \n",
    "    Throws:\n",
    "        IndexOutOfBoundsError if 'point' cannot be indexed or has at least two elements.\n",
    "    \"\"\"\n",
    "    degree = (45 * 2 * pi) / 360\n",
    "    return [point[0] * cos(degree) - point[1] * sin(degree), point[0] * sin(degree) + point[1] * cos(degree)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def gen_images(locs, features, n_gridpoints, normalize=True,\n",
    "#                augment=False, pca=False, std_mult=0.1, n_components=2, edgeless=False):\n",
    "# needs defined: locs, features, n_gridpoints\n",
    "\n",
    "# earlier interpolation function. Not as 'general', but supports rotation.\n",
    "\n",
    "def interpolate(locs, features, n_gridpoints=32, rotate=True, edge_channels=[0, 6, 12, 21]):\n",
    "    \"\"\"\n",
    "    Generates EEG images given electrode locations in 2D space and multiple feature values for each electrode\n",
    "\n",
    "    Args:\n",
    "        locs: An array with shape [n_electrodes, 2]\n",
    "            containing X, Y coordinates for each electrode.\n",
    "        features: Feature matrix as [n_samples, n_features]\n",
    "            Features are as columns. Features corresponding\n",
    "            to each frequency band are concatenated.\n",
    "            (alpha1, alpha2, ..., beta1, beta2,...)\n",
    "        n_gridpoints: Number of pixels in the output images.\n",
    "            Default=32\n",
    "        rotate: If the whole image should be rotated by 45 degrees \n",
    "            and fit to a square.\n",
    "            Default=True\n",
    "        edge_channels: The indices of the channels with the highest, \n",
    "            leftmost, rightmost and lowest coordinates.\n",
    "            Only relevant when rotating.\n",
    "            (Assuming that Fz is on the x axis to the right.)\n",
    "    \n",
    "    Returns:\n",
    "        Tensor of size [samples, colors, W, H] containing\n",
    "        generated images.\n",
    "    \"\"\"\n",
    "    \n",
    "    if rotate:\n",
    "        high_x = locs[edge_channels[0]][0]\n",
    "        high_y = locs[edge_channels[1]][1]\n",
    "        low_y  = locs[edge_channels[2]][1]\n",
    "        low_x  = locs[edge_channels[3]][0]\n",
    "        \n",
    "        t_x = abs(high_x) + abs(low_x)\n",
    "        t_y = abs(high_y) + abs(low_y)\n",
    "        \n",
    "        factor = t_y / t_x\n",
    "        \n",
    "        # centering:\n",
    "        xdiff = (high_x + low_x) / 2\n",
    "        ydiff = (high_y + low_y) / 2\n",
    "        \n",
    "        locst = zip(map(lambda x: (x - xdiff) * factor, fst(locs)),\n",
    "                    map(lambda y: (y - ydiff), snd(locs)))\n",
    "        \n",
    "        locs = np.array(list(map(rotate2D, locst)))\n",
    "    \n",
    "    cut = lambda a: a if len(a.shape) < 3 else a[:, :, 0]\n",
    "    \n",
    "    feat_array_temp = []\n",
    "    nElectrodes = locs.shape[0]     # Number of electrodes\n",
    "    # Test whether the feature vector length is divisible by number of electrodes\n",
    "    assert features.shape[1] % nElectrodes == 0\n",
    "    n_colors = int(features.shape[1] / nElectrodes)\n",
    "    for c in range(n_colors):\n",
    "        feat_array_temp.append(cut(features[:, c * nElectrodes : nElectrodes * (c+1)]))\n",
    "    nSamples = features.shape[0]\n",
    "    # getting some surrounding values right\n",
    "    grid_x, grid_y = np.mgrid[\n",
    "                     min(locs[:, 0]):max(locs[:, 0]):n_gridpoints*1j,\n",
    "                     min(locs[:, 1]):max(locs[:, 1]):n_gridpoints*1j\n",
    "                     ]\n",
    "    temp_interp = []\n",
    "    for c in range(n_colors):\n",
    "        temp_interp.append(np.zeros([nSamples, n_gridpoints, n_gridpoints]))\n",
    "    # Interpolating\n",
    "    for i in range(nSamples):\n",
    "        for c in range(n_colors):\n",
    "            temp_interp[c][i, :, :] = cut(griddata(locs, feat_array_temp[c][i, :], (grid_x, grid_y),\n",
    "                                    method='cubic', fill_value=np.nan))\n",
    "    #                                 method='cubic', fill_value=np.nan)# [:, :, 0]\n",
    "    #                                 method='cubic', fill_value=np.nan)\n",
    "        print('Interpolating {0}/{1}'.format(i+1, nSamples), end='\\r')\n",
    "    images = np.swapaxes(np.asarray(temp_interp), 0, 1)     # swap axes to have [samples, colors, W, H]\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a relatively ordered list including the mapping \n",
    "# of each of the channels to a location in a 19x11 grid.\n",
    "# Various other channels exist, so note that this list is not complete.\n",
    "tight_cap_positions = [\n",
    "    ['', '', '', '', 'Fp1', 'FPz', 'Fp2', '', '', '', ''],\n",
    "    ['', '', '', 'AFp3h', '', '', '', 'Afp4h', '', '', ''],\n",
    "    ['', 'AF7', 'AF5', 'AF3', 'AF1', 'AFz', 'AF2', 'AF4', 'AF6', 'AF8', ''],\n",
    "    ['', '', 'AFF5h', '', 'AFF1', '', 'AFF2', '', 'AFF6h', '', ''],\n",
    "    ['', 'F7', 'F5', 'F3', 'F1', 'Fz', 'F2', 'F4', 'F6', 'F8', ''],\n",
    "    ['FFT9h', 'FFT7h', 'FFC5h', 'FFC3h', 'FFC1h', '', 'FFC2h', 'FFC4h', 'FFC6h', 'FFT8h', 'FFT10h'],\n",
    "    ['FT9', 'FT7', 'FC5', 'FC3', 'FC1', 'FCz', 'FC2', 'FC4', 'FC6', 'FT8', 'FT10'],\n",
    "    ['FTT9h', 'FTT7h', 'FCC5h', 'FCC3h', 'FCC1h', '', 'FCC2h', 'FCC4h', 'FCC6h', 'FTT8h', 'FTT10h'],\n",
    "    ['M1', 'T7', 'C5', 'C3', 'C1', 'Cz', 'C2', 'C4', 'C6', 'T8', 'M2'],\n",
    "    ['', 'TTP7h', 'CCP5h', 'CCP3h', 'CCP1h', '', 'CCP2h', 'CCP4h', 'CCP6h', 'TTP8h', ''],\n",
    "    ['TP9', 'TP7', 'CP5', 'CP3', 'CP1', 'CPz', 'CP2', 'CP4', 'CP6', 'TP8', 'TP10'],\n",
    "    ['TPP9h', 'TPP7h', 'CPP5h', 'CPP3h', 'CPP1h', '', 'CPP2h', 'CPP4h', 'CPP6h', 'TPP8h', 'TPP10h'],\n",
    "    ['P9', 'P7', 'P5', 'P3', 'P1', 'Pz', 'P2', 'P4', 'P6', 'P8', 'P10'],\n",
    "    ['PPO9h', '', 'PPO5h', '', 'PPO1', '', 'PPO2', '', 'PPO6h', '', 'PPO10h'],\n",
    "    ['PO9', 'PO7', 'PO5', 'PO3', 'PO1', 'POz', 'PO2', 'PO4', 'PO6', 'PO8', 'PO10'],\n",
    "    ['POO9h', '', '', 'POO3h', '', '', '', 'POO4h', '', '', 'POO10h'],\n",
    "    ['', '', '', '', 'O1', 'Oz', 'O2', '', '', '', ''],\n",
    "    ['', '', '', '', 'OI1h', '', 'OI2h', '', '', '', ''],\n",
    "    ['', '', '', '', 'I1', 'Iz', 'I2', '', '', '', '']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapper(locs):\n",
    "    \"\"\" This is a higher-order-function, returning a function which will,\n",
    "    If you give it a list of values, map them to the corresponding location\n",
    "    given from the 'locs' specifier.\n",
    "    To be more specific, 'locs' provides the relative index for the values,\n",
    "    the mapping happens from the 'locs' based locations to the locations\n",
    "    provided by tight_cap_positions.\n",
    "    \n",
    "    Mapper Creation: O(1)\n",
    "    Actual Mapping: O(11x19x|locs|)\n",
    "    \n",
    "    Full function signature:\n",
    "        mapper :: [[String]] -> ([[Num]] -> np.[[Num]])\n",
    "    \n",
    "    Args:\n",
    "        locs (list): a list of channels, of type [[String]], an\n",
    "            Empty string denoting that no channel be mapped there.\n",
    "        \n",
    "    Returns:\n",
    "        func\n",
    "    \"\"\"\n",
    "    def actual(values):\n",
    "        nmap = np.empty((19, 11))\n",
    "        for i, row in enumerate(tight_cap_positions):\n",
    "            for j, col in enumerate(row):\n",
    "                if col in locs:\n",
    "                    ind = locs.index(col)\n",
    "                    nmap[i, j] = values[ind]\n",
    "                else:\n",
    "                    nmap[i, j] = np.nan\n",
    "        return nmap\n",
    "    return actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapper2(locs):\n",
    "    \"\"\" This is a higher-order linear function. Functionality\n",
    "    is the same as 'mapper', as well as type signature.\n",
    "    It is supposed to be faster than mapper, and requires the\n",
    "    original mapper for map creation.\n",
    "    \n",
    "    Suposedly faster, especially for larger |locs| values.\n",
    "    \n",
    "    Also, this structure can be considerably sped up with\n",
    "    current caching/pipelining/processor architecture techniques,\n",
    "    in comparison to the 'normal' mapper function. So even though\n",
    "    it might seem worse complexity-wise (even if only by a constant factor),\n",
    "    it is worth a shot, as 'mapper' is bound to irritate the\n",
    "    processor considerably, whereas this function does not.\n",
    "    \n",
    "    Also, mapping does not return 'NaN's if there is no result,\n",
    "    but f64 zeros.\n",
    "    \n",
    "    Mapper Creation: O(11x19x(|locs| + c))\n",
    "    Actual Mapping: O(129x209 + c)\n",
    "    \"\"\"\n",
    "    \n",
    "    res = mapper(locs)(list(range(len(locs))))\n",
    "    res = res.reshape(209)\n",
    "    matrix = np.zeros((209, 129))\n",
    "    for i, value in enumerate(res):\n",
    "        if not np.isnan(value):\n",
    "            matrix[i, int(value)] = 1\n",
    "    return lambda v: matrix.dot(v).reshape((19, 11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are all channels (in this order) from the High-Gamma Dataset.\n",
    "positions = [\n",
    "    'Fp1', 'Fp2', 'Fpz', 'F7', 'F3', 'Fz', 'F4', 'F8', 'FC5',\n",
    "    'FC1', 'FC2', 'FC6', 'M1', 'T7', 'C3', 'Cz', 'C4', 'T8', 'M2',\n",
    "    'CP5', 'CP1', 'CP2', 'CP6', 'P7', 'P3', 'Pz', 'P4', 'P8', 'POz',\n",
    "    'O1', 'Oz', 'O2', 'AF7', 'AF3', 'AF4', 'AF8', 'F5', 'F1',\n",
    "    'F2', 'F6', 'FC3', 'FCz', 'FC4', 'C5', 'C1', 'C2', 'C6', 'CP3',\n",
    "    'CPz', 'CP4', 'P5', 'P1', 'P2', 'P6', 'PO5', 'PO3', 'PO4', 'PO6',\n",
    "    'FT7', 'FT8', 'TP7', 'TP8', 'PO7', 'PO8', 'FT9', 'FT10', 'TPP9h',\n",
    "    'TPP10h', 'PO9', 'PO10', 'P9', 'P10', 'AFF1', 'AFz', 'AFF2', 'FFC5h',\n",
    "    'FFC3h', 'FFC4h', 'FFC6h', 'FCC5h', 'FCC3h', 'FCC4h', 'FCC6h',\n",
    "    'CCP5h', 'CCP3h', 'CCP4h', 'CCP6h', 'CPP5h', 'CPP3h', 'CPP4h',\n",
    "    'CPP6h', 'PPO1', 'PPO2', 'I1', 'Iz', 'I2', 'AFp3h', 'AFp4h', 'AFF5h',\n",
    "    'AFF6h', 'FFT7h', 'FFC1h', 'FFC2h', 'FFT8h', 'FTT9h', 'FTT7h',\n",
    "    'FCC1h', 'FCC2h', 'FTT8h', 'FTT10h', 'TTP7h', 'CCP1h', 'CCP2h',\n",
    "    'TTP8h', 'TPP7h', 'CPP1h', 'CPP2h', 'TPP8h', 'PPO9h', 'PPO5h',\n",
    "    'PPO6h', 'PPO10h', 'POO9h', 'POO3h', 'POO4h', 'POO10h', 'OI1h',\n",
    "    'OI2h', 'STI 014']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bbci_data(filename, low_cut_hz):\n",
    "    \"\"\" Provided loader function. Might need a rewrite on it's own.\n",
    "    \"\"\"\n",
    "    load_sensor_names = None\n",
    "\n",
    "    # we loaded all sensors to always get same cleaning results independent of sensor selection\n",
    "    # There is an inbuilt heuristic that tries to use only EEG channels and that definitely\n",
    "    # works for datasets in our paper\n",
    "    loader = BBCIDataset(filename, load_sensor_names=load_sensor_names)\n",
    "\n",
    "    log.info(\"Loading data...\")\n",
    "    cnt = loader.load()\n",
    "\n",
    "    # Cleaning: First find all trials that have absolute microvolt values\n",
    "    # larger than +- 800 inside them and remember them for removal later\n",
    "    log.info(\"Cutting trials...\")\n",
    "\n",
    "    marker_def = OrderedDict([('Right Hand', [1]), ('Left Hand', [2],),\n",
    "                              ('Rest', [3]), ('Feet', [4])])\n",
    "    clean_ival = [0, 4000]\n",
    "\n",
    "    set_for_cleaning = create_signal_target_from_raw_mne(cnt, marker_def,\n",
    "                                                  clean_ival)\n",
    "\n",
    "    clean_trial_mask = np.max(np.abs(set_for_cleaning.X), axis=(1, 2)) < 800\n",
    "\n",
    "    log.info(\"Clean trials: {:3d}  of {:3d} ({:5.1f}%)\".format(\n",
    "        np.sum(clean_trial_mask),\n",
    "        len(set_for_cleaning.X),\n",
    "        np.mean(clean_trial_mask) * 100))\n",
    "\n",
    "    # Further preprocessings as descibed in paper\n",
    "\n",
    "    log.info(\"Resampling...\")\n",
    "\n",
    "    # now the original frequency is actually 500Hz,\n",
    "    # so we can resample to everything below that.\n",
    "    cnt = resample_cnt(cnt, 50.0)\n",
    "\n",
    "    log.info(\"Highpassing...\")\n",
    "    cnt = mne_apply(\n",
    "        lambda a: highpass_cnt(\n",
    "            a, low_cut_hz, cnt.info['sfreq'], filt_order=3, axis=1),\n",
    "        cnt)\n",
    "    log.info(\"Standardizing...\")\n",
    "    cnt = mne_apply(\n",
    "        lambda a: exponential_running_standardize(a.T, factor_new=1e-3,\n",
    "                                                  init_block_size=1000,\n",
    "                                                  eps=1e-4).T,\n",
    "        cnt)\n",
    "\n",
    "    # Trial interval, start at -500 already, since improved decoding for networks\n",
    "    ival = [-500, 4000]\n",
    "\n",
    "    dataset = create_signal_target_from_raw_mne(cnt, marker_def, ival)\n",
    "    dataset.X = dataset.X[clean_trial_mask]\n",
    "    dataset.y = dataset.y[clean_trial_mask]\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class LazyHGDLoader:\n",
    "    \"\"\" LazyLoader of High-Gamma BBCI Dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    # adjust FILENAME template as needed.\n",
    "    FILENAME = \"/datadisk/Coding/high-gamma-dataset/data/%s/%i.mat\"\n",
    "    dataset_number = None\n",
    "    low_cut_hz = 4\n",
    "\n",
    "    def __init__(self, number: int, low_cut_hz: int = 4):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            number (int): The number of the Dataset to be loaded.\n",
    "            low_cut_hz (int): The lower threshold for cutting frequencies.\n",
    "                Default=4\n",
    "        \"\"\"\n",
    "        self.dataset_number = number\n",
    "        self.low_cut_hz = low_cut_hz\n",
    "\n",
    "    @property\n",
    "    def train(self):\n",
    "        try:\n",
    "            return self.train_set\n",
    "        except AttributeError:\n",
    "            filename = self.FILENAME % ('train', self.dataset_number)\n",
    "            self.train_set = load_bbci_data(filename=filename, low_cut_hz=low_cut_hz)\n",
    "\n",
    "    @property\n",
    "    def test(self):\n",
    "        try:\n",
    "            return self.test_set\n",
    "        except AttributeError:\n",
    "            filename = self.FILENAME % ('test', self.dataset_number)\n",
    "            self.test_set = load_bbci_data(filename=filename, low_cut_hz=low_cut_hz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate2(features, ch_names=None, ch_mapper=None, grid_x=11, grid_y=19, method='linear'):\n",
    "    \"\"\" More recent interpolation function. Also, much faster. Does not support Rotation. though.\n",
    "    \n",
    "    Args:\n",
    "        features (array-like): the values between which will be interpolated.\n",
    "        ch_names ([str]): Optional list with the order of channels from 'features'.\n",
    "        ch_mapper (mapper): Optional Channel to Location mapper.\n",
    "        grid_x (int): \n",
    "        grid_y (int): \n",
    "        method (str): \n",
    "    \n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    assert ch_mapper or ch_names, \"needs either channel names or a mapper instance!\"\n",
    "    if not ch_mapper:\n",
    "        ch_mapper = mapper2(ch_names)\n",
    "\n",
    "    locs = list(map(tuple, np.argwhere(~np.isnan(ch_mapper(features[0, :, 0])))))\n",
    "\n",
    "    result = np.empty((features.shape[0], grid_y * grid_x, features.shape[2]))\n",
    "\n",
    "    for trial in range(features.shape[0]):\n",
    "        for frame in range(features.shape[2]):\n",
    "            r = ch_mapper(features[trial, :, frame])\n",
    "            res = griddata(locs, r[~np.isnan(r)], tuple(np.mgrid[0:grid_y, 0:grid_x]), method=method)\n",
    "            res = res.reshape(grid_y * grid_x)\n",
    "            result[trial, :, frame] = res\n",
    "\n",
    "        print(\"Interpolating: %s/%s\" % (trial, features.shape[0]), end='\\r')\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_labels(label, classes=4):\n",
    "    \"\"\" Classic One-Hot encoding for the labels.\n",
    "    Args:\n",
    "        label (array-like): The actual labels,\n",
    "            Numbers from 0 to classes-1.\n",
    "        classes (int): The number of distinct categories to encode.\n",
    "            Default=4\n",
    "    \n",
    "    Returns:\n",
    "        PyTorch Tensor containing One-Hot encodings of the labels.\n",
    "    \"\"\"\n",
    "    one_hot = torch.zeros(label.shape[0], classes)\n",
    "    one_hot[torch.arange(label.shape[0]), label] = 1\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_load_compute_save(filename: str, func: callable):\n",
    "    \"\"\" Small helper function. Try to load the given\n",
    "    File if the filename exists, and otherwise compute and save it.\n",
    "    \n",
    "    Args:\n",
    "        filename (str): Name of the file that should be loaded.\n",
    "        func (callable): Function to compute and return the data,\n",
    "            if it was not found as a file with 'filename'.\n",
    "    \n",
    "    Returns:\n",
    "        The content of the loading-, or computing-operation.\n",
    "    \"\"\"\n",
    "    import pickle\n",
    "    try:\n",
    "        with open(filename, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            log.info(\"Succeeded loading \" + filename + \".\")\n",
    "    except FileNotFoundError:\n",
    "        log.info(\"Computing \" + filename + \". This might take some time.\")\n",
    "        data = func()\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(data, f)\n",
    "    return data\n",
    "\n",
    "tlcs = lambda fn, fu: try_load_compute_save(fn, fu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-10 20:41:35,821 INFO : Loading interpolated image data.\n",
      "2019-11-10 20:41:36,148 INFO : Succeeded loading images_hgd.\n",
      "2019-11-10 20:41:36,150 INFO : Succeeded loading labels_hgd.\n",
      "2019-11-10 20:41:36,227 INFO : Succeeded loading images_test_hgd.\n",
      "2019-11-10 20:41:36,228 INFO : Succeeded loading labels_test_hgd.\n",
      "2019-11-10 20:41:36,229 INFO : Successfully loaded interpolated images\n"
     ]
    }
   ],
   "source": [
    "# This is the main functionality.\n",
    "#\n",
    "# Basically, 'load the values from cache', if they are there,\n",
    "# if not, compute them, and for that 'load the training set from cache'\n",
    "# if it is there, if not, recompute it from the RAW Data as well.\n",
    "\n",
    "# creation of a hgd loader for the set with number 2.\n",
    "hgd = LazyHGDLoader(2)\n",
    "r = mapper2(positions)\n",
    "\n",
    "log.info(\"Loading interpolated image data.\")\n",
    "\n",
    "# Do note that calling 'hgd.train.X' does not evaluate 'hgd.train' yet.\n",
    "# Also, it will only be computed at most once, even if it would be required for both.\n",
    "images = tlcs('images_hgd', lambda: interpolate2(hgd.train.X, ch_mapper=r))\n",
    "labels = tlcs('labels_hgd', lambda: one_hot_labels(hgd.train.y))\n",
    "\n",
    "# same here.\n",
    "images_test = tlcs('images_test_hgd', lambda: interpolate2(hgd.test.X, ch_mapper=r))\n",
    "labels_test = tlcs('labels_test_hgd', lambda: one_hot_labels(hgd.test.y))\n",
    "\n",
    "\n",
    "log.info(\"Successfully loaded interpolated images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
